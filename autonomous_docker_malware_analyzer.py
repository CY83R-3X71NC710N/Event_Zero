#!/usr/bin/env python3
"""
Autonomous Docker-Based Malware Analyzer
100% Self-Contained - No External Dependencies Required

This script creates a Docker container and uses AI to comprehensively analyze malware
until EVERY behavior is mapped out in plain English. The AI has full autonomy to
install any tools, packages, or utilities needed for complete analysis.
"""

import os
import sys
import json
import time
import hashlib
import argparse
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional

class AutonomousDockerMalwareAnalyzer:
    """
    Fully autonomous malware analyzer that uses Docker for isolation
    and AI for comprehensive analysis until 100% behavior mapping is achieved.
    """
    
    def __init__(self, gemini_api_key: str = None):
        self.gemini_api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        if not self.gemini_api_key:
            print("‚ùå GEMINI_API_KEY environment variable required!")
            print("   Set it with: export GEMINI_API_KEY='your-api-key'")
            sys.exit(1)
        
        self.docker_image = "blackarchlinux/blackarch"
        # Use a consistent container name for reuse
        self.container_name = "blackarch_malware_analyzer"
        self.analysis_complete = False
        self.analysis_iterations = 0
        self.max_iterations = 50  # AI decides when to stop, this is just a safety limit
        self.analysis_results = {}
        self.verbose = True  # Enhanced output mode
        
        print(f"üöÄ Autonomous Docker Malware Analyzer Initialized")
        print(f"üì¶ Container: {self.container_name}")
        print(f"üêß Base Image: BlackArch Linux (1000+ security tools)")
        print(f"üîë API Key: {'‚úÖ Set (' + self.gemini_api_key[:15] + '...)' if self.gemini_api_key else '‚ùå Missing'}")
        print(f"üîß Verbose Mode: {'‚úÖ Enabled' if self.verbose else '‚ùå Disabled'}")
        print(f"üéØ Max Iterations: {self.max_iterations}")
        print(f"‚è∞ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    def check_docker(self) -> bool:
        """Check if Docker is available and running"""
        try:
            result = subprocess.run(['docker', '--version'], 
                                  capture_output=True, text=True, check=True)
            print(f"‚úÖ Docker available: {result.stdout.strip()}")
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("‚ùå Docker not found or not running!")
            print("   Please install Docker and ensure it's running.")
            return False
    
    def check_existing_container(self) -> bool:
        """Check if a container with our name already exists"""
        try:
            print(f"\nüîç Checking for existing container: {self.container_name}")
            
            # Check for running containers
            result = subprocess.run(['docker', 'ps', '--filter', f'name={self.container_name}', '--format', '{{.Names}}'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0 and self.container_name in result.stdout:
                print(f"‚úÖ Found running container: {self.container_name}")
                return True
            
            # Check for stopped containers
            result = subprocess.run(['docker', 'ps', '-a', '--filter', f'name={self.container_name}', '--format', '{{.Names}}'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0 and self.container_name in result.stdout:
                print(f"üîÑ Found stopped container: {self.container_name}")
                print(f"üöÄ Starting existing container...")
                
                start_result = subprocess.run(['docker', 'start', self.container_name], 
                                            capture_output=True, text=True)
                if start_result.returncode == 0:
                    print(f"‚úÖ Successfully started existing container")
                    return True
                else:
                    print(f"‚ùå Failed to start existing container: {start_result.stderr}")
                    print(f"üßπ Removing problematic container...")
                    subprocess.run(['docker', 'rm', '-f', self.container_name], capture_output=True)
                    return False
            
            print(f"‚ÑπÔ∏è  No existing container found")
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error checking existing container: {e}")
            return False

    def check_existing_image(self) -> bool:
        """Check if we already have a built BlackArch analyzer image"""
        try:
            # Check for consistent image name
            image_name = 'blackarch_malware_analyzer'
            
            print(f"üîç Checking for existing image: {image_name}")
            
            result = subprocess.run(['docker', 'images', '--filter', f'reference={image_name}', '--format', '{{.Repository}}:{{.Tag}}'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0 and image_name in result.stdout:
                print(f"‚úÖ Found existing analyzer image: {image_name}")
                self.reuse_image = image_name
                return True
            
            # Check for any malware_analyzer or blackarch_malware images
            result = subprocess.run(['docker', 'images', '--filter', 'reference=*malware_analyzer*', '--format', '{{.Repository}}:{{.Tag}}'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout.strip():
                images = result.stdout.strip().split('\n')
                print(f"üîç Found existing analyzer images:")
                for img in images[:3]:  # Show first 3
                    print(f"   üì¶ {img}")
                if len(images) > 3:
                    print(f"   üì¶ ... and {len(images) - 3} more")
                
                # Use the first one found
                latest_image = images[0].split(':')[0]
                print(f"‚ôªÔ∏è  Will reuse existing image: {latest_image}")
                self.reuse_image = latest_image
                return True
            
            print(f"‚ÑπÔ∏è  No existing analyzer images found")
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error checking existing images: {e}")
            return False

    def create_analysis_container(self, malware_path: str) -> bool:
        """Create or reuse Docker container with malware sample for analysis"""
        try:
            print("\nüîß CONTAINER MANAGEMENT PHASE")
            print("=" * 50)
            
            # Check for existing container first
            if self.check_existing_container():
                print(f"‚ôªÔ∏è  Reusing existing container: {self.container_name}")
                
                # Copy malware file to existing container
                print(f"üìÑ Copying malware file to existing container...")
                copy_cmd = ['docker', 'cp', malware_path, f'{self.container_name}:/analysis/malware_sample']
                result = subprocess.run(copy_cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"‚úÖ Malware file copied successfully")
                    
                    # Make executable if needed
                    self.execute_in_container('chmod +x /analysis/malware_sample 2>/dev/null || true')
                    
                    # Test container connectivity
                    print(f"\nüîç Testing container connectivity...")
                    returncode, stdout, stderr = self.execute_in_container('echo "Container reuse successful" && python3 --version', timeout=30)
                    
                    if returncode == 0:
                        print(f"‚úÖ Container connectivity verified")
                        print(f"üêç Python version: {stdout.split()[-1] if stdout else 'Unknown'}")
                        return True
                    else:
                        print(f"‚ùå Container connectivity test failed: {stderr}")
                        print(f"üßπ Removing problematic container...")
                        subprocess.run(['docker', 'rm', '-f', self.container_name], capture_output=True)
                        # Fall through to create new container
                else:
                    print(f"‚ùå Failed to copy malware file: {result.stderr}")
                    print(f"üßπ Removing problematic container...")
                    subprocess.run(['docker', 'rm', '-f', self.container_name], capture_output=True)
                    # Fall through to create new container
            
            # Analyze malware file first
            file_size = os.path.getsize(malware_path)
            print(f"üìÑ Malware File: {malware_path}")
            print(f"üìè File Size: {file_size:,} bytes ({file_size/1024:.2f} KB)")
            
            
            # Calculate hash
            with open(malware_path, 'rb') as f:
                file_data = f.read()
                file_hash = hashlib.sha256(file_data).hexdigest()
                md5_hash = hashlib.md5(file_data).hexdigest()
            
            print(f"üîë SHA256: {file_hash}")
            print(f"üîë MD5: {md5_hash}")
            
            # Check if we can reuse an existing image
            reuse_image = None
            if hasattr(self, 'reuse_image'):
                reuse_image = self.reuse_image
            elif self.check_existing_image():
                reuse_image = getattr(self, 'reuse_image', None)
            
            if reuse_image:
                print(f"\n‚ôªÔ∏è  Using existing analyzer image: {reuse_image}")
                image_tag = reuse_image
            else:
                print(f"\nüî® Building new BlackArch analyzer image...")
                
                # Copy malware to temporary location for Docker
                malware_filename = Path(malware_path).name
                temp_dir = tempfile.mkdtemp()
                temp_malware_path = os.path.join(temp_dir, malware_filename)
                
                with open(malware_path, 'rb') as src, open(temp_malware_path, 'wb') as dst:
                    dst.write(src.read())
                
                print(f"üìÅ Temporary Directory: {temp_dir}")
                print(f"üìÅ Temporary Malware Copy: {temp_malware_path}")
                print(f"‚úÖ File copied successfully")
                
                # Create Dockerfile for analysis environment
                print(f"\nüê≥ Creating Dockerfile for BlackArch analysis environment...")
                dockerfile_content = f"""
FROM blackarchlinux/blackarch

ENV LANG=C.UTF-8
ENV LC_ALL=C.UTF-8

# System updates and base packages (no comments in pacman commands)
RUN pacman -Syu --noconfirm
RUN pacman -S --noconfirm python python-requests python-pip git curl wget vim nano
RUN python -m pip install --user --break-system-packages google-generativeai
ENV PATH="/root/.local/bin:$PATH"

WORKDIR /analysis
COPY {malware_filename} /analysis/malware_sample
RUN chmod +x /analysis/malware_sample 2>/dev/null || true

CMD ["/bin/bash"]
"""
                
                dockerfile_path = os.path.join(temp_dir, 'Dockerfile')
                with open(dockerfile_path, 'w') as f:
                    f.write(dockerfile_content)
                
                print(f"üìÑ Dockerfile created: {dockerfile_path}")
                print(f"üì¶ Base Image: BlackArch Linux")
                print(f"üõ†Ô∏è  Available Tools: 1000+ security tools via pacman")
                
                image_tag = 'blackarch_malware_analyzer'
                print(f"üè∑Ô∏è  Image Tag: {image_tag}")
                
                print(f"\nüî® Building Docker analysis environment...")
                print(f"‚è∞ Build started at: {time.strftime('%H:%M:%S')}")
                build_cmd = [
                    'docker', 'build', 
                    '-t', image_tag,
                    temp_dir
                ]
                
                print(f"üõ†Ô∏è  Build command: {' '.join(build_cmd)}")
                
                # Run build with real-time output
                process = subprocess.Popen(build_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
                
                build_output = []
                while True:
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        line = output.strip()
                        build_output.append(line)
                        if self.verbose and any(keyword in line.lower() for keyword in ['step', 'sha256:', 'extracting', 'done']):
                            print(f"   üîß {line}")
                
                returncode = process.poll()
                
                if returncode != 0:
                    print(f"‚ùå Docker build failed with exit code: {returncode}")
                    print("üìã Full build output:")
                    for line in build_output[-20:]:  # Show last 20 lines
                        print(f"   {line}")
                    return False
                
                print(f"‚úÖ Docker image built successfully")
                print(f"‚è∞ Build completed at: {time.strftime('%H:%M:%S')}")
                
                # Cleanup temp directory
                print(f"\nüßπ Cleaning up temporary files...")
                os.system(f"rm -rf {temp_dir}")
                print(f"‚úÖ Temporary directory cleaned: {temp_dir}")
            
            # Start container
            print(f"\nüöÄ Starting analysis container...")
            run_cmd = [
                'docker', 'run',
                '-d',  # Detached mode
                '--name', self.container_name,
                '--rm',  # Remove container when it stops
                '-e', f'GEMINI_API_KEY={self.gemini_api_key}',
                image_tag,
                'sleep', 'infinity'  # Keep container running
            ]
            
            print(f"üõ†Ô∏è  Run command: {' '.join(run_cmd[:7])}... [GEMINI_API_KEY] ...")
            
            result = subprocess.run(run_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                print(f"‚ùå Container start failed: {result.stderr}")
                return False
            
            container_id = result.stdout.strip()
            print(f"‚úÖ Analysis container started successfully")
            print(f"üÜî Container ID: {container_id[:12]}...")
            print(f"üìõ Container Name: {self.container_name}")
            
            # If we didn't use an existing image, copy the malware file
            if not reuse_image:
                print(f"üìÑ Malware file already included in image")
            else:
                print(f"üìÑ Copying malware file to reused container...")
                copy_cmd = ['docker', 'cp', malware_path, f'{self.container_name}:/analysis/malware_sample']
                result = subprocess.run(copy_cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"‚úÖ Malware file copied successfully")
                    self.execute_in_container('chmod +x /analysis/malware_sample 2>/dev/null || true')
                else:
                    print(f"‚ùå Failed to copy malware file: {result.stderr}")
                    return False
            
            # Verify container is running
            check_cmd = ['docker', 'ps', '--filter', f'name={self.container_name}', '--format', 'table {{.Names}}\t{{.Status}}\t{{.Image}}']
            result = subprocess.run(check_cmd, capture_output=True, text=True)
            if result.returncode == 0 and self.container_name in result.stdout:
                print(f"‚úÖ Container verification successful")
                print(f"üìä Container Status:")
                for line in result.stdout.strip().split('\n'):
                    print(f"   {line}")
            
            # Test container connectivity
            print(f"\nüîç Testing container connectivity...")
            test_cmd = 'echo "Container test successful" && python3 --version && command -v python3'
            returncode, stdout, stderr = self.execute_in_container(test_cmd, timeout=30)
            
            if returncode == 0 or "Container test successful" in stdout:
                print(f"‚úÖ Container connectivity test passed")
                if "Python" in stdout:
                    python_version = [line for line in stdout.split('\n') if 'Python' in line]
                    if python_version:
                        print(f"üêç Python version: {python_version[0].strip()}")
            else:
                print(f"‚ö†Ô∏è  Container connectivity test had warnings: {stderr}")
                print(f"üìã But container appears to be running normally")
            
            # Cleanup temp directory if it was created
            if 'temp_dir' in locals():
                print(f"\nüßπ Cleaning up temporary files...")
                os.system(f"rm -rf {temp_dir}")
                print(f"‚úÖ Temporary directory cleaned: {temp_dir}")
            
            print(f"\n‚úÖ CONTAINER CREATION COMPLETE")
            print(f"üì¶ Ready for autonomous analysis")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Container creation failed: {e}")
            import traceback
            print(f"üîç Exception details:")
            traceback.print_exc()
            return False
    
    def execute_in_container(self, command: str, timeout: int = 300) -> tuple:
        """Execute command in the analysis container"""
        try:
            if self.verbose:
                print(f"üõ†Ô∏è  Executing: {command[:100]}{'...' if len(command) > 100 else ''}")
                print(f"‚è±Ô∏è  Timeout: {timeout}s")
            
            exec_cmd = [
                'docker', 'exec',
                self.container_name,
                'bash', '-c', command
            ]
            
            start_time = time.time()
            result = subprocess.run(exec_cmd, capture_output=True, text=True, timeout=timeout)
            execution_time = time.time() - start_time
            
            if self.verbose:
                print(f"‚úÖ Execution completed in {execution_time:.2f}s")
                print(f"üìä Return code: {result.returncode}")
                if result.stdout:
                    stdout_preview = result.stdout[:200] + "..." if len(result.stdout) > 200 else result.stdout
                    print(f"üì§ STDOUT preview: {stdout_preview}")
                if result.stderr:
                    stderr_preview = result.stderr[:200] + "..." if len(result.stderr) > 200 else result.stderr
                    print(f"üì§ STDERR preview: {stderr_preview}")
            
            return result.returncode, result.stdout, result.stderr
            
        except subprocess.TimeoutExpired:
            error_msg = f"Command timed out after {timeout} seconds"
            if self.verbose:
                print(f"‚è∞ {error_msg}")
            return -1, "", error_msg
        except Exception as e:
            error_msg = str(e)
            if self.verbose:
                print(f"‚ùå Execution failed: {error_msg}")
            return -1, "", error_msg
    
    def call_gemini_api(self, prompt: str) -> str:
        """Call Gemini API for analysis with rate limiting and retry logic"""
        import time
        
        max_retries = 3
        base_delay = 60  # Start with 60 seconds delay for rate limit
        
        for attempt in range(max_retries):
            try:
                print(f"\nü§ñ CALLING GEMINI API (Attempt {attempt + 1}/{max_retries})")
                print("=" * 30)
                print(f"üìù Prompt length: {len(prompt)} characters")
                print(f"üîë API Key: {self.gemini_api_key[:15]}...")
                print(f"‚è∞ Request time: {time.strftime('%H:%M:%S')}")
                
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # Exponential backoff
                    print(f"‚è≥ Rate limit detected, waiting {delay} seconds before retry...")
                    time.sleep(delay)
                
                # Create Python script to call Gemini API inside container
                api_script = f'''
import google.generativeai as genai
import json
import sys
import time

print("ü§ñ Initializing Gemini API in BlackArch environment...")
try:
    genai.configure(api_key="{self.gemini_api_key}")
    model = genai.GenerativeModel('gemini-1.5-flash')

    prompt = """
{prompt}
"""

    print(f"üìù Prompt length: {{len(prompt)}} characters")
    print(f"‚è∞ Sending request at: {{time.strftime('%H:%M:%S')}}")
    print(f"üêß BlackArch environment ready with 1000+ security tools")

    response = model.generate_content(prompt)
    print(f"‚úÖ Response received at: {{time.strftime('%H:%M:%S')}}")
    print(f"üìè Response length: {{len(response.text)}} characters")
    print("__GEMINI_RESPONSE_START__")
    print(response.text)
    print("__GEMINI_RESPONSE_END__")
except Exception as e:
    print(f"‚ùå API Error: {{e}}")
    print(f"‚ùå Error type: {{type(e).__name__}}")
    import traceback
    traceback.print_exc()
    print(f"__GEMINI_ERROR__: {{str(e)}}")
    sys.exit(1)
'''
                
                print(f"üìÑ Writing API script to container...")
                # Write script to container
                returncode, stdout, stderr = self.execute_in_container(
                    f'cat > /analysis/gemini_call.py << \'EOF\'\n{api_script}\nEOF'
                )
                
                if returncode != 0:
                    error_msg = f"Error writing API script: {stderr}"
                    print(f"‚ùå {error_msg}")
                    return f"ERROR: {error_msg}"
                
                print(f"‚úÖ API script written successfully")
                
                # Execute API call
                print(f"üöÄ Executing API call...")
                returncode, stdout, stderr = self.execute_in_container(
                    'cd /analysis && python3 gemini_call.py',
                    timeout=180  # Increase timeout to 3 minutes
                )
                
                print(f"üìä API call completed with return code: {returncode}")
                
                if returncode == 137:
                    error_msg = "API call was killed (likely due to memory/timeout issues)"
                    print(f"‚ùå {error_msg}")
                    print(f"üìã STDOUT: {stdout[:300]}...")
                    print(f"üìã STDERR: {stderr[:300]}...")
                    
                    # Check if it's a rate limit in the output before being killed
                    if "429" in stdout or "rate" in stdout.lower() or "quota" in stdout.lower():
                        print(f"üîÑ Rate limit detected before process was killed, will retry...")
                        if attempt < max_retries - 1:
                            continue
                        else:
                            return f"ERROR: Rate limit exceeded after {max_retries} attempts"
                    else:
                        return f"ERROR: {error_msg}"
                elif returncode != 0:
                    error_msg = f"API call failed with code {returncode}: {stderr}"
                    print(f"‚ùå {error_msg}")
                    print(f"üìã STDOUT: {stdout[:300]}...")
                    
                    # Check if it's a rate limit error
                    if "429" in stdout or "rate" in stdout.lower() or "quota" in stdout.lower():
                        print(f"üîÑ Rate limit detected, will retry with backoff...")
                        if attempt < max_retries - 1:
                            continue
                        else:
                            return f"ERROR: Rate limit exceeded after {max_retries} attempts"
                    else:
                        return f"ERROR: {error_msg}"
                
                # Extract response
                if "__GEMINI_RESPONSE_START__" in stdout and "__GEMINI_RESPONSE_END__" in stdout:
                    start_marker = "__GEMINI_RESPONSE_START__"
                    end_marker = "__GEMINI_RESPONSE_END__"
                    start_idx = stdout.find(start_marker) + len(start_marker)
                    end_idx = stdout.find(end_marker)
                    response_text = stdout[start_idx:end_idx].strip()
                    
                    print(f"‚úÖ Successfully extracted API response")
                    print(f"üìè Response length: {len(response_text)} characters")
                    print(f"üìù Response preview: {response_text[:150]}...")
                    
                    return response_text
                else:
                    error_msg = f"Failed to extract API response from output"
                    print(f"‚ùå {error_msg}")
                    print(f"üìã Full stdout: {stdout[:500]}...")
                    
                    # Check for rate limit in full output
                    if "429" in stdout or "rate" in stdout.lower() or "quota" in stdout.lower():
                        print(f"üîÑ Rate limit detected in output, will retry...")
                        if attempt < max_retries - 1:
                            continue
                        else:
                            return f"ERROR: Rate limit exceeded after {max_retries} attempts"
                    
                    return f"ERROR: {error_msg}"
                    
            except Exception as e:
                error_msg = f"Gemini API call failed: {e}"
                print(f"‚ùå {error_msg}")
                import traceback
                traceback.print_exc()
                
                if attempt < max_retries - 1:
                    print(f"üîÑ Will retry after delay...")
                    continue
                else:
                    return f"ERROR: {error_msg}"
        
        return f"ERROR: Failed after {max_retries} attempts"
    
    def perform_autonomous_analysis(self) -> Dict[str, Any]:
        """Perform autonomous analysis until AI deems it complete"""
        print(f"\nü§ñ STARTING AUTONOMOUS MALWARE ANALYSIS")
        print("=" * 60)
        print(f"üéØ Mission: Map EVERY behavior until 100% understanding")
        print(f"üîÑ Max iterations: {self.max_iterations}")
        print(f"‚è∞ Analysis started: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üì¶ Container: {self.container_name}")
        
        # Initial analysis prompt
        initial_prompt = """
You are an expert malware reverse engineer with UNLIMITED AUTONOMY in a BlackArch Linux Docker container.

MISSION: Analyze the malware sample at /analysis/malware_sample until you have mapped out 
EVERY SINGLE BEHAVIOR in plain English. Do not stop until you have 100% understanding.

CRITICAL: The malware file is located at /analysis/malware_sample (NOT malware_sample.exe)

YOUR CAPABILITIES:
- Full BlackArch Linux with 1000+ security tools available
- Optimized pacman mirrors for fastest downloads
- Smart package management that checks for existing installations
- Create Python scripts to automate analysis
- Run tools and parse their outputs
- Combine multiple tools for comprehensive analysis

AVAILABLE BLACKARCH TOOL CATEGORIES:
- Static Analysis: radare2, ghidra, ida-free, binwalk, strings, hexdump, objdump, readelf
- Dynamic Analysis: strace, ltrace, gdb, valgrind, frida
- Disassemblers: capstone, keystone, radare2, objdump
- Forensics: volatility, sleuthkit, autopsy, foremost
- Network Analysis: wireshark, tcpdump, netcat, nmap
- Reverse Engineering: upx, unrar, 7zip, file, xxd
- Malware Analysis: yara, clamav, virustotal-cli, maldet
- Binary Analysis: peda, pwntools, checksec, ropper
- And 900+ more tools available via pacman

SMART PACKAGE MANAGEMENT:
Use this Python function for ALL package installations:

def smart_install_package(package_name):
    import subprocess
    
    # Check if package is already installed
    check_cmd = f'pacman -Qi {package_name} >/dev/null 2>&1'
    if subprocess.call(['bash', '-c', check_cmd]) == 0:
        print(f"‚úÖ {package_name} already installed, skipping")
        return True
    
    # Install package if not present
    try:
        print(f"üì¶ Installing {package_name}...")
        subprocess.run(['pacman', '-S', '--noconfirm', package_name], check=True)
        print(f"‚úÖ {package_name} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {package_name}: {e}")
        return False

CRITICAL PACKAGE NOTES:
- 'strings' tool is included in 'binutils' package (already installed)
- Use 'binutils' instead of 'strings' package
- 'wireshark' is called 'wireshark-qt' in BlackArch
- 'tshark' is included with 'wireshark-qt'
- 'radare2-extras' doesn't exist, use 'radare2-cutter' or just 'radare2'
- 'python-frida' for Frida Python bindings (not just 'frida')

ANALYSIS REQUIREMENTS:
1. Use smart_install_package() for ALL package installations
2. Map EVERY function, system call, library call, API usage
3. Identify ALL file operations, network operations, process operations
4. Extract ALL strings, constants, embedded data, configurations
5. Understand the complete execution flow from start to finish
6. Identify malware family, techniques, persistence mechanisms
7. Explain what EVERY instruction/operation does in plain English
8. Create a complete behavioral profile

AUTONOMOUS OPERATION WORKFLOW:
1. Install tools using smart_install_package() function (checks for existing installations)
2. Read tool documentation using man pages or --help
3. Execute tools with appropriate parameters on /analysis/malware_sample
4. Parse and analyze tool outputs
5. Create Python scripts to automate complex analysis
6. Correlate findings from multiple tools
7. Continue until you have ZERO unknowns

MIRROR OPTIMIZATION (run once at start):
# Update pacman database for latest packages (BlackArch uses standard pacman)
subprocess.run(['pacman', '-Sy'], capture_output=True)

OUTPUT FORMAT:
Return Python code that performs the next analysis step. The code should:
1. Optimize mirrors if not done already
2. Use smart_install_package() for any needed BlackArch tools
3. Execute analysis tools with proper parameters on /analysis/malware_sample
4. Parse tool outputs and extract insights
5. Store results in /analysis/results.json
6. Set analysis_complete=True only when 100% mapped
7. Include detailed plain English explanations

EXAMPLE TOOL INSTALLATION:
# Define the smart installation function first
def smart_install_package(package_name):
    import subprocess
    
    # Check if package is already installed
    check_cmd = f'pacman -Qi {package_name} >/dev/null 2>&1'
    if subprocess.call(['bash', '-c', check_cmd]) == 0:
        print(f"‚úÖ {package_name} already installed, skipping")
        return True
    
    print(f"üì¶ Installing {package_name}...")
    try:
        subprocess.run(['pacman', '-S', '--noconfirm', package_name], check=True)
        print(f"‚úÖ {package_name} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {package_name}: {e}")
        return False

# Then use it for installations
smart_install_package('radare2')
smart_install_package('python-frida')
smart_install_package('yara')

EXAMPLE ANALYSIS (use correct file path):
file_result = subprocess.run(['file', '/analysis/malware_sample'], capture_output=True, text=True)
strings_result = subprocess.run(['strings', '/analysis/malware_sample'], capture_output=True, text=True)

Start with comprehensive static analysis using multiple BlackArch tools.
Do NOT declare completion until every behavior is understood.

Begin analysis now - leverage the full BlackArch arsenal for complete behavioral mapping.
"""
        
        analysis_start_time = time.time()
        consecutive_api_failures = 0
        max_consecutive_failures = 3
        
        while not self.analysis_complete and self.analysis_iterations < self.max_iterations:
            self.analysis_iterations += 1
            iteration_start_time = time.time()
            
            print(f"\nüîÑ ANALYSIS ITERATION {self.analysis_iterations}")
            print("=" * 60)
            print(f"‚è∞ Iteration started: {time.strftime('%H:%M:%S')}")
            print(f"üéØ Goal: {'Initial comprehensive analysis' if self.analysis_iterations == 1 else 'Continue behavioral mapping'}")
            
            # Get AI analysis instructions
            if self.analysis_iterations == 1:
                print(f"üìù Using initial analysis prompt")
                ai_response = self.call_gemini_api(initial_prompt)
            else:
                # Get current analysis state
                print(f"üìä Retrieving current analysis state...")
                returncode, current_results, stderr = self.execute_in_container(
                    'cat /analysis/results.json 2>/dev/null || echo "{}"'
                )
                
                if current_results.strip():
                    try:
                        results_data = json.loads(current_results)
                        print(f"‚úÖ Found existing results: {len(results_data)} keys")
                        for key in list(results_data.keys())[:5]:  # Show first 5 keys
                            print(f"   üìã {key}")
                        if len(results_data) > 5:
                            print(f"   üìã ... and {len(results_data) - 5} more")
                    except json.JSONDecodeError:
                        print(f"‚ö†Ô∏è  Could not parse existing results")
                else:
                    print(f"‚ÑπÔ∏è  No existing results found")
                
                continuation_prompt = f"""
Continue autonomous malware analysis using BlackArch tools. Current iteration: {self.analysis_iterations}

Current analysis state:
{current_results}

BLACKARCH CAPABILITIES:
- 1000+ security tools available via pacman
- Optimized mirrors for fastest downloads
- Smart package management prevents reinstallation
- Advanced malware analysis suite included
- Access to latest reverse engineering tools

SMART PACKAGE MANAGEMENT:
Use this function for ALL package installations to avoid reinstallation:

```python
def smart_install_package(package_name):
    import subprocess
    
    # Check if package is already installed
    check_cmd = f'pacman -Qi {{package_name}} >/dev/null 2>&1'
    if subprocess.call(['bash', '-c', check_cmd]) == 0:
        print(f"‚úÖ {{package_name}} already installed, skipping")
        return True
    
    print(f"üì¶ Installing {{package_name}}...")
    try:
        subprocess.run(['pacman', '-S', '--noconfirm', package_name], check=True)
        print(f"‚úÖ {{package_name}} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {{package_name}}: {{e}}")
        return False
```

REQUIREMENTS:
- Use smart_install_package() for ALL installations
- Review what has been discovered so far
- Identify what is still unknown or needs deeper analysis
- Install additional BlackArch tools as needed
- Use specialized tools for areas not yet fully understood
- Create Python scripts to automate complex analysis workflows
- Continue until EVERY behavior is mapped in plain English

CORRECTED PACKAGE NAMES:
- Use 'python-frida' instead of 'frida'
- Use 'wireshark-qt' instead of 'wireshark'
- Use 'radare2-cutter' instead of 'radare2-extras'
- 'strings' is in 'binutils' (already installed)
- Use 'tcpdump' (available in repos)
- Use 'yara' (available in repos)

AVAILABLE TOOL CATEGORIES:
- blackarch-malware: malware analysis tools
- blackarch-reversing: reverse engineering tools  
- blackarch-forensic: forensic analysis tools
- blackarch-binary: binary analysis tools
- blackarch-debugger: debugging tools
- blackarch-disassembler: disassembly tools

If analysis is truly 100% complete (every behavior mapped), set analysis_complete=True.
Otherwise, perform the next analysis step using appropriate BlackArch tools.

Return Python code for the next analysis phase leveraging BlackArch capabilities.
"""
                print(f"üìù Using continuation prompt")
                ai_response = self.call_gemini_api(continuation_prompt)
            
            # Check if API call failed
            if ai_response.startswith("ERROR:"):
                print(f"‚ùå AI API Error in iteration {self.analysis_iterations}: {ai_response}")
                consecutive_api_failures += 1
                
                # If too many consecutive failures, use fallback analysis
                if consecutive_api_failures >= max_consecutive_failures:
                    print(f"üîß Too many API failures ({consecutive_api_failures}), using fallback analysis...")
                    python_code = self.fallback_analysis()
                    consecutive_api_failures = 0  # Reset counter
                else:
                    # If it's a rate limit error, wait and continue
                    if "rate limit" in ai_response.lower() or "429" in ai_response:
                        print(f"‚è≥ Rate limit hit, waiting 2 minutes before next iteration...")
                        time.sleep(120)  # Wait 2 minutes
                        continue
                    else:
                        print(f"‚è≥ API error, waiting 60 seconds before retry...")
                        time.sleep(60)
                        continue
            else:
                consecutive_api_failures = 0  # Reset counter on success
            
            # Check for actual errors (not just code starting with ```python)
            if ai_response.startswith("ERROR:") or "__GEMINI_ERROR__" in ai_response:
                print(f"‚ùå AI Error in iteration {self.analysis_iterations}: {ai_response}")
                consecutive_api_failures += 1
                
                if consecutive_api_failures >= max_consecutive_failures:
                    print(f"üîß Using fallback analysis due to repeated errors...")
                    python_code = self.fallback_analysis()
                    consecutive_api_failures = 0
                else:
                    print(f"‚è≥ Waiting 60 seconds before retry...")
                    time.sleep(60)
                    continue
            
            print(f"\nüß† AI ANALYSIS INSTRUCTIONS (Iteration {self.analysis_iterations})")
            print("-" * 50)
            
            # Extract Python code from AI response (unless it's a real error)
            if not ai_response.startswith("ERROR:") and "__GEMINI_ERROR__" not in ai_response:
                print(f"üìÑ FULL AI RESPONSE:")
                print("=" * 80)
                print(ai_response)
                print("=" * 80)
                
                print(f"üîç Extracting Python code from AI response...")
                python_code = self.extract_python_code(ai_response)
                if not python_code or len(python_code.strip()) < 10:
                    print("‚ùå No valid executable code found in AI response")
                    print(f"üìã AI response was: {ai_response[:200]}...")
                    consecutive_api_failures += 1
                    
                    if consecutive_api_failures >= max_consecutive_failures:
                        print(f"üîß Using fallback analysis due to code extraction failures...")
                        python_code = self.fallback_analysis()
                        consecutive_api_failures = 0
                    else:
                        print(f"‚è≥ Waiting 30 seconds before next iteration...")
                        time.sleep(30)
                        continue
            else:
                print(f"üìÑ Using fallback analysis code")
                print("-" * 50)
                python_code = self.fallback_analysis()
            
            print(f"‚úÖ Extracted Python code ({len(python_code)} characters)")
            print(f"üìù FULL EXTRACTED CODE:")
            print("-" * 60)
            print(python_code)
            print("-" * 60)
            
            # Write and execute analysis code
            code_file = f'/analysis/iteration_{self.analysis_iterations}.py'
            write_cmd = f'cat > {code_file} << \'EOF\'\n{python_code}\nEOF'
            
            print(f"\nüìÑ Writing analysis code to {code_file}...")
            returncode, stdout, stderr = self.execute_in_container(write_cmd)
            if returncode != 0:
                print(f"‚ùå Failed to write analysis code: {stderr}")
                break
            
            print(f"‚úÖ Analysis code written successfully")
            
            print(f"\n‚öôÔ∏è  EXECUTING ANALYSIS ITERATION {self.analysis_iterations}")
            print("-" * 40)
            execution_start = time.time()
            
            # Execute with real-time output streaming
            exec_cmd = [
                'docker', 'exec',
                self.container_name,
                'bash', '-c', f'cd /analysis && python3 {code_file}'
            ]
            
            print(f"üöÄ Starting execution with real-time output...")
            process = subprocess.Popen(exec_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, universal_newlines=True)
            
            stdout_lines = []
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    line = output.strip()
                    stdout_lines.append(line)
                    print(f"üì§ {line}")  # Show real-time output
            
            returncode = process.poll()
            stdout = '\n'.join(stdout_lines)
            stderr = ""  # Combined with stdout
            
            execution_time = time.time() - execution_start
            
            # SELF-HEALING: If code execution failed, analyze error and generate fix
            if returncode != 0:
                print(f"\nüîß SELF-HEALING MODE ACTIVATED")
                print("-" * 50)
                print(f"‚ùå Code execution failed with exit code: {returncode}")
                print(f"üß† AI will analyze the error and generate corrected code...")
                
                # Extract error information
                error_info = self.extract_error_info(stdout, stderr, python_code)
                print(f"üîç Error Analysis: {error_info}")
                
                # Ask AI to fix the code
                healing_response = self.generate_healing_code(python_code, error_info, self.analysis_iterations)
                
                if not healing_response.startswith("ERROR:"):
                    print(f"üîß APPLYING SELF-HEALING FIX")
                    print("-" * 40)
                    
                    # Extract the fixed code
                    fixed_code = self.extract_python_code(healing_response)
                    if fixed_code and len(fixed_code.strip()) > 10:
                        print(f"üìÑ FULL HEALING RESPONSE:")
                        print("=" * 60)
                        print(healing_response)
                        print("=" * 60)
                        
                        print(f"‚úÖ Extracted fixed code ({len(fixed_code)} characters)")
                        print(f"üìù FIXED CODE:")
                        print("-" * 40)
                        print(fixed_code)
                        print("-" * 40)
                        
                        # Write and execute the fixed code
                        fixed_code_file = f'/analysis/iteration_{self.analysis_iterations}_fixed.py'
                        write_cmd = f'cat > {fixed_code_file} << \'EOF\'\n{fixed_code}\nEOF'
                        
                        print(f"üìÑ Writing fixed code to {fixed_code_file}...")
                        fix_returncode, fix_stdout, fix_stderr = self.execute_in_container(write_cmd)
                        
                        if fix_returncode == 0:
                            print(f"‚úÖ Fixed code written successfully")
                            
                            # Execute the fixed code
                            print(f"\nüîß EXECUTING SELF-HEALED CODE")
                            print("-" * 30)
                            
                            fix_exec_cmd = [
                                'docker', 'exec',
                                self.container_name,
                                'bash', '-c', f'cd /analysis && python3 {fixed_code_file}'
                            ]
                            
                            print(f"üöÄ Starting fixed code execution...")
                            fix_process = subprocess.Popen(fix_exec_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, universal_newlines=True)
                            
                            fix_stdout_lines = []
                            while True:
                                output = fix_process.stdout.readline()
                                if output == '' and fix_process.poll() is not None:
                                    break
                                if output:
                                    line = output.strip()
                                    fix_stdout_lines.append(line)
                                    print(f"üîß {line}")  # Show real-time healing output
                            
                            fix_returncode = fix_process.poll()
                            stdout = '\n'.join(fix_stdout_lines)  # Use fixed execution output
                            returncode = fix_returncode  # Update return code
                            
                            if fix_returncode == 0:
                                print(f"‚úÖ SELF-HEALING SUCCESSFUL!")
                                print(f"üéØ Fixed code executed without errors")
                            else:
                                print(f"‚ö†Ô∏è  Self-healing attempted but still has issues (code {fix_returncode})")
                                print(f"üí° Will continue with original output for analysis")
                        else:
                            print(f"‚ùå Failed to write fixed code: {fix_stderr}")
                    else:
                        print(f"‚ùå Could not extract valid fixed code from healing response")
                else:
                    print(f"‚ùå Healing API call failed: {healing_response}")
            
            else:
                print(f"‚úÖ Code executed successfully (exit code: {returncode})")
            
            print(f"üìä EXECUTION RESULTS (Iteration {self.analysis_iterations})")
            print(f"‚è±Ô∏è  Execution time: {execution_time:.2f} seconds")
            print(f"üìä Return Code: {returncode}")
            
            if stdout:
                stdout_lines = stdout.strip().split('\n')
                print(f"üì§ STDOUT ({len(stdout_lines)} lines):")
                # Show first 10 and last 5 lines if output is long
                if len(stdout_lines) > 15:
                    for i, line in enumerate(stdout_lines[:10]):
                        print(f"   {i+1:2d}: {line}")
                    print(f"   ... ({len(stdout_lines) - 15} lines omitted) ...")
                    for i, line in enumerate(stdout_lines[-5:], len(stdout_lines) - 4):
                        print(f"   {i:2d}: {line}")
                else:
                    for i, line in enumerate(stdout_lines, 1):
                        print(f"   {i:2d}: {line}")
            
            if stderr:
                stderr_lines = stderr.strip().split('\n')
                print(f"üì§ STDERR ({len(stderr_lines)} lines):")
                for i, line in enumerate(stderr_lines[:10], 1):  # Show first 10 lines of errors
                    print(f"   {i:2d}: {line}")
                if len(stderr_lines) > 10:
                    print(f"   ... ({len(stderr_lines) - 10} more error lines)")
            
            # Check if analysis is complete
            print(f"\nüîç Checking analysis completion status...")
            returncode, results_content, stderr = self.execute_in_container(
                'cat /analysis/results.json 2>/dev/null || echo "{}"'
            )
            
            try:
                results = json.loads(results_content) if results_content.strip() else {}
                print(f"üìä Results file status: {len(results)} keys found")
                
                if results.get('analysis_complete', False):
                    self.analysis_complete = True
                    self.analysis_results = results
                    print("‚úÖ AI has declared analysis 100% complete!")
                    
                    # Show completion summary
                    if 'confidence_score' in results:
                        print(f"üéØ Final confidence: {results['confidence_score']}")
                    if 'behavioral_summary' in results:
                        summary = results['behavioral_summary']
                        print(f"üß† Behavioral summary preview: {summary[:200]}...")
                    
                    break
                else:
                    completion_status = results.get('analysis_complete', 'Not set')
                    print(f"üîÑ Analysis not yet complete (status: {completion_status})")
                    
                    # Show current progress
                    if 'progress_percentage' in results:
                        print(f"üìà Progress: {results['progress_percentage']}%")
                    if 'next_steps' in results:
                        print(f"üìã Next steps: {results['next_steps']}")
                        
            except json.JSONDecodeError:
                print("‚ö†Ô∏è  Could not parse results.json")
                print(f"üìã Raw content: {results_content[:200]}...")
            
            iteration_time = time.time() - iteration_start_time
            print(f"\n‚è±Ô∏è  Iteration {self.analysis_iterations} completed in {iteration_time:.2f} seconds")
            
            # Brief pause between iterations
            if not self.analysis_complete:
                print(f"‚è∏Ô∏è  Pausing 3 seconds before next iteration...")
                time.sleep(3)
        
        total_analysis_time = time.time() - analysis_start_time
        
        # Get final results
        print(f"\nüìã FINAL ANALYSIS SUMMARY")
        print("=" * 40)
        print(f"‚è±Ô∏è  Total analysis time: {total_analysis_time:.2f} seconds ({total_analysis_time/60:.1f} minutes)")
        print(f"üîÑ Total iterations: {self.analysis_iterations}")
        print(f"‚úÖ Analysis complete: {self.analysis_complete}")
        
        if not self.analysis_complete:
            print(f"‚ö†Ô∏è  Analysis stopped after {self.analysis_iterations} iterations (max: {self.max_iterations})")
            print(f"üí° Reasons analysis may have stopped:")
            print(f"   - Reached maximum iteration limit")
            print(f"   - AI encountered unrecoverable error")
            print(f"   - User interruption")
        
        print(f"\nüìÑ Retrieving final results...")
        returncode, final_results, stderr = self.execute_in_container(
            'cat /analysis/results.json 2>/dev/null || echo "{}"'
        )
        
        try:
            self.analysis_results = json.loads(final_results) if final_results.strip() else {}
            print(f"‚úÖ Final results retrieved: {len(self.analysis_results)} keys")
            
            # Show key findings
            for key in ['threat_level', 'confidence_score', 'malware_family', 'file_type']:
                if key in self.analysis_results:
                    print(f"   üìä {key}: {self.analysis_results[key]}")
                    
        except json.JSONDecodeError:
            print("‚ùå Could not parse final results")
            self.analysis_results = {"error": "Could not parse final results", "raw_content": final_results[:500]}
        
        return self.analysis_results
    
    def fallback_analysis(self) -> str:
        """Fallback analysis when API is unavailable - basic static analysis with smart package management"""
        print(f"üîß Using fallback analysis - basic static analysis with optimized package management")
        
        fallback_code = """
import subprocess
import json
import os

print("üîß Starting fallback static analysis with smart package management...")

# Smart package installation function
def smart_install_package(package_name):
    import subprocess
    
    # Check if package is already installed
    check_cmd = f'pacman -Qi {package_name} >/dev/null 2>&1'
    if subprocess.call(['bash', '-c', check_cmd]) == 0:
        print(f"‚úÖ {package_name} already installed, skipping")
        return True
    
    print(f"üì¶ Installing {package_name}...")
    try:
        subprocess.run(['pacman', '-S', '--noconfirm', package_name], check=True)
        print(f"‚úÖ {package_name} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {package_name}: {e}")
        return False

# Optimize mirrors for faster downloads
print("üöÄ Optimizing pacman mirrors...")
try:
    subprocess.run(['pacman-mirrors', '--fasttrack'], capture_output=True, timeout=60)
    subprocess.run(['pacman', '-Sy'], capture_output=True, timeout=60)
    print("‚úÖ Pacman mirrors optimized")
except Exception as e:
    print(f"‚ö†Ô∏è Mirror optimization failed: {e}")

# Initialize results
results = {
    "analysis_method": "fallback_static_analysis_optimized",
    "timestamp": "2025-07-26",
    "analysis_complete": False,
    "progress_percentage": 25,
    "findings": {}
}

# Install essential tools with smart management
print("üõ†Ô∏è Installing essential analysis tools...")
smart_install_package('yara')
smart_install_package('python-frida')

# Basic file analysis
print("üìã Running basic file analysis...")
try:
    # Get file type
    file_result = subprocess.run(['file', '/analysis/malware_sample'], 
                                capture_output=True, text=True)
    if file_result.returncode == 0:
        results['findings']['file_type'] = file_result.stdout.strip()
        print(f"üìÑ File type: {file_result.stdout.strip()}")
    
    # Get strings (binutils already installed)
    strings_result = subprocess.run(['strings', '/analysis/malware_sample'], 
                                   capture_output=True, text=True)
    if strings_result.returncode == 0:
        strings_list = strings_result.stdout.strip().split('\\n')[:50]  # First 50 strings
        results['findings']['strings_sample'] = strings_list
        print(f"üìù Found {len(strings_list)} interesting strings")
    
    # Get hexdump preview
    hexdump_result = subprocess.run(['hexdump', '-C', '/analysis/malware_sample'], 
                                   capture_output=True, text=True)
    if hexdump_result.returncode == 0:
        hex_lines = hexdump_result.stdout.strip().split('\\n')[:20]  # First 20 lines
        results['findings']['hex_preview'] = hex_lines
        print(f"üîç Hex dump preview captured")
    
    # Check if it's an ELF binary
    if 'ELF' in results['findings'].get('file_type', ''):
        print("üîç ELF binary detected, running readelf...")
        readelf_result = subprocess.run(['readelf', '-h', '/analysis/malware_sample'], 
                                       capture_output=True, text=True)
        if readelf_result.returncode == 0:
            results['findings']['elf_header'] = readelf_result.stdout.strip()
            print("‚úÖ ELF header analysis complete")
    
    results['findings']['basic_analysis_complete'] = True
    results['next_steps'] = "Need AI API to continue comprehensive analysis"
    
except Exception as e:
    print(f"‚ùå Fallback analysis error: {e}")
    results['error'] = str(e)

# Save results
print("üíæ Saving fallback analysis results...")
with open('/analysis/results.json', 'w') as f:
    json.dump(results, f, indent=2)

print("‚úÖ Fallback analysis complete")
print("üí° Optimized package management prevents unnecessary reinstallations")
"""
        return fallback_code

    def extract_error_info(self, stdout: str, stderr: str, original_code: str) -> str:
        """Extract meaningful error information from execution output"""
        error_lines = []
        
        # Look for common error patterns in stdout
        for line in stdout.split('\n'):
            if any(keyword in line.lower() for keyword in [
                'error:', 'traceback', 'exception', 'failed', 'not found', 
                'calledprocesserror', 'subprocess.calledprocesserror', 'target not found'
            ]):
                error_lines.append(line.strip())
        
        # Look for specific package installation errors
        if 'target not found' in stdout.lower():
            # Extract the package name that wasn't found
            for line in stdout.split('\n'):
                if 'target not found:' in line:
                    package_name = line.split('target not found:')[-1].strip()
                    error_lines.append(f"Package '{package_name}' not found in pacman repositories")
        
        # Look for Python errors
        if 'CalledProcessError' in stdout:
            error_lines.append("Command execution failed - likely package installation issue")
        
        return '; '.join(error_lines) if error_lines else "Unknown execution error"
    
    def generate_healing_code(self, original_code: str, error_info: str, iteration: int) -> str:
        """Generate corrected code based on error analysis"""
        healing_prompt = f"""
SELF-HEALING MODE: Fix the failed Python code

ORIGINAL CODE THAT FAILED:
```python
{original_code}
```

ERROR INFORMATION:
{error_info}

ANALYSIS CONTEXT:
- This is iteration {iteration} of autonomous malware analysis
- Running in BlackArch Linux Docker container
- Code failed during execution and needs immediate fixing
- The malware file is located at /analysis/malware_sample (NOT malware_sample.exe)

COMMON BLACKARCH PACKAGE ISSUES:
1. 'strings' package doesn't exist - use 'binutils' which includes strings (already installed)
2. 'wireshark' should be 'wireshark-qt' in BlackArch
3. 'tshark' is included with 'wireshark-qt' package
4. 'radare2-extras' doesn't exist - use 'radare2-cutter' or just 'radare2'
5. 'frida' should be 'python-frida' for Python bindings
6. Some tools may already be installed (file, objdump, readelf are in base system)
7. Use smart package detection to avoid reinstalling

SMART PACKAGE MANAGEMENT SOLUTION:
Replace ALL pacman installation commands with this function:

```python
def smart_install_package(package_name):
    import subprocess
    
    # Check if package is already installed
    check_cmd = f'pacman -Qi {package_name} >/dev/null 2>&1'
    if subprocess.call(['bash', '-c', check_cmd]) == 0:
        print(f"‚úÖ {package_name} already installed, skipping")
        return True
    
    print(f"üì¶ Installing {package_name}...")
    try:
        subprocess.run(['pacman', '-S', '--noconfirm', package_name], check=True)
        print(f"‚úÖ {package_name} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {package_name}: {e}")
        return False
```

COMMON FILE PATH ISSUES:
- Use '/analysis/malware_sample' NOT 'malware_sample.exe' or 'malware.exe'
- The file already exists in the container at /analysis/malware_sample
- Always use the full absolute path

HEALING REQUIREMENTS:
1. Replace ALL 'subprocess.run(['pacman'...])' with 'smart_install_package()'
2. Fix package installation commands to use correct BlackArch package names
3. Correct any file path references to use /analysis/malware_sample
4. Add error handling for packages that might already be installed
5. Ensure the corrected code can complete the malware analysis task
6. Keep the same analysis logic but fix the installation/execution issues
7. Add fallback options for tools that might not be available

BLACKARCH PACKAGE CORRECTIONS:
- Instead of 'strings' ‚Üí tool already available via binutils (no installation needed)
- Instead of 'wireshark' ‚Üí use 'wireshark-qt'
- Instead of 'frida' ‚Üí use 'python-frida'
- Instead of 'radare2-extras' ‚Üí use 'radare2-cutter' or skip if not needed
- Instead of 'tshark' ‚Üí install 'wireshark-qt' (includes tshark)
- Instead of 'pestudio' ‚Üí not available in BlackArch, skip or use alternative
- Instead of 'x64dbg' ‚Üí not available in BlackArch, use gdb or radare2

MIRROR OPTIMIZATION (add at start if not present):
```python
# Optimize pacman database for faster downloads (run once)
if not os.path.exists('/analysis/db_updated'):
    print("üì¶ Updating pacman database...")
    subprocess.run(['pacman', '-Sy'], capture_output=True)
    os.makedirs('/analysis', exist_ok=True)
    open('/analysis/db_updated', 'a').close() # create a dummy file to mark update
```

FILE PATH CORRECTIONS:
- Replace any reference to 'malware_sample.exe' with '/analysis/malware_sample'
- Replace any reference to 'malware.exe' with '/analysis/malware_sample'
- Replace any reference to 'suspicious.dll' with '/analysis/malware_sample'

OUTPUT: Return the corrected Python code that will execute successfully.
Focus on fixing the immediate errors while maintaining the analysis functionality.

```python
# Fixed version of the code here
```
"""
        
        print(f"üîß Generating healing code for iteration {iteration}...")
        return self.call_gemini_api(healing_prompt)
    
    def extract_python_code(self, text: str) -> str:
        """Extract Python code from AI response"""
        import re
        
        # Look for code blocks
        patterns = [
            r'```python\n(.*?)\n```',
            r'```\n(.*?)\n```',
            r'<code>(.*?)</code>',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.DOTALL)
            if matches:
                return matches[0].strip()
        
        # If no code blocks found, look for Python-like content
        lines = text.split('\n')
        python_lines = []
        in_code = False
        
        for line in lines:
            if any(line.strip().startswith(keyword) for keyword in ['import ', 'from ', 'def ', 'class ', 'if ', 'for ', 'while ', 'try:']):
                in_code = True
            
            if in_code:
                python_lines.append(line)
                
            # Stop at certain markers
            if in_code and (line.strip() == '' and len(python_lines) > 5):
                break
        
        return '\n'.join(python_lines) if python_lines else text
    
    def cleanup_container(self):
        """Clean up Docker container (but keep image for reuse)"""
        try:
            print(f"üßπ Cleaning up container: {self.container_name}")
            subprocess.run(['docker', 'stop', self.container_name], 
                          capture_output=True, text=True)
            # Note: We keep the image for reuse, only remove container
            print("‚úÖ Container cleanup complete")
        except Exception as e:
            print(f"‚ö†Ô∏è  Cleanup warning: {e}")
    
    def generate_final_report(self, malware_path: str) -> str:
        """Generate comprehensive final analysis report"""
        report_timestamp = int(time.time())
        
        # Calculate file hash
        with open(malware_path, 'rb') as f:
            file_data = f.read()
            file_hash = hashlib.sha256(file_data).hexdigest()
        
        report = {
            "analysis_metadata": {
                "timestamp": report_timestamp,
                "analyzer_version": "Autonomous Docker Analyzer v1.0",
                "malware_file": malware_path,
                "file_size": len(file_data),
                "sha256": file_hash,
                "analysis_iterations": self.analysis_iterations,
                "analysis_complete": self.analysis_complete,
                "container_name": self.container_name
            },
            "comprehensive_analysis": self.analysis_results,
            "ai_confidence": self.analysis_results.get('confidence_score', 0.0),
            "threat_assessment": self.analysis_results.get('threat_level', 'Unknown'),
            "behavioral_mapping": self.analysis_results.get('behavioral_summary', 'Not available')
        }
        
        # Save report
        report_file = f"autonomous_analysis_report_{report_timestamp}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"üìÑ Final report saved: {report_file}")
        return report_file
    
    def analyze_malware(self, malware_path: str) -> Dict[str, Any]:
        """Main analysis orchestration method"""
        if not os.path.isfile(malware_path):
            raise FileNotFoundError(f"Malware file not found: {malware_path}")
        
        if not self.check_docker():
            raise RuntimeError("Docker not available")
        
        try:
            # Create analysis environment
            if not self.create_analysis_container(malware_path):
                raise RuntimeError("Failed to create analysis container")
            
            # Perform autonomous analysis
            results = self.perform_autonomous_analysis()
            
            # Generate final report
            report_file = self.generate_final_report(malware_path)
            
            return {
                "success": True,
                "analysis_complete": self.analysis_complete,
                "iterations": self.analysis_iterations,
                "report_file": report_file,
                "results": results
            }
            
        finally:
            # Always cleanup
            self.cleanup_container()

def main():
    """Main execution function"""
    print("üî¨ AUTONOMOUS DOCKER MALWARE ANALYZER")
    print("=" * 60)
    print("üöÄ 100% Self-Contained - AI-Driven Complete Behavioral Mapping")
    print("üê≥ Uses Docker for safe isolation")
    print("ü§ñ AI has full autonomy to install tools and perform analysis")
    print("üéØ Continues until EVERY behavior is mapped in plain English")
    print("=" * 60)
    
    parser = argparse.ArgumentParser(description="Autonomous Docker Malware Analyzer")
    parser.add_argument('--file', '-f', type=str, required=True,
                       help='Path to malware file to analyze')
    parser.add_argument('--api-key', type=str,
                       help='Gemini API key (or set GEMINI_API_KEY env var)')
    
    args = parser.parse_args()
    
    try:
        # Initialize analyzer
        analyzer = AutonomousDockerMalwareAnalyzer(gemini_api_key=args.api_key)
        
        print(f"üéØ Target: {args.file}")
        print(f"üìä Starting comprehensive autonomous analysis...")
        
        # Perform analysis
        results = analyzer.analyze_malware(args.file)
        
        print("\n" + "=" * 60)
        print("üìã AUTONOMOUS ANALYSIS COMPLETE!")
        print("=" * 60)
        print(f"‚úÖ Success: {results['success']}")
        print(f"üîÑ Iterations: {results['iterations']}")
        print(f"‚úÖ Complete: {results['analysis_complete']}")
        print(f"üìÑ Report: {results['report_file']}")
        
        if results['results']:
            confidence = results['results'].get('confidence_score', 0)
            threat = results['results'].get('threat_level', 'Unknown')
            print(f"üéØ Confidence: {confidence}")
            print(f"‚ö†Ô∏è  Threat Level: {threat}")
            
            # Show behavioral summary if available
            behavioral = results['results'].get('behavioral_summary', '')
            if behavioral:
                print(f"\nüß† BEHAVIORAL MAPPING:")
                print("-" * 40)
                print(behavioral[:500] + "..." if len(behavioral) > 500 else behavioral)
        
        print(f"\nüìä Full analysis results saved to: {results['report_file']}")
        
    except KeyboardInterrupt:
        print("\nüõë Analysis interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Analysis failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
